{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OpenAI Gym CartPole Environment\n",
    "\n",
    "![](CartPole.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAI Gym website contains information about widely used environments for testing reinforcement learning algorithms. It is at [https://gym.openai.com/](https://gym.openai.com/). This notebook demonstrates the steps to go through the Getting Started information at [Getting Started with Gym](https://gym.openai.com/docs/).\n",
    "\n",
    "OpenAI Gym also has a GitHub site at [https://github.com/openai/gym/](https://github.com/openai/gym/). More information about the CartPole problem can be found at [CartPole Wiki](https://github.com/openai/gym/wiki/CartPole-v0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## OpenAI Gym Installation ##\n",
    "OpenAI gym is not installed as part of the Anaconda Python or standard Python distributions.  You need to install it from your command prompt or terminal. \n",
    "\n",
    "For Anaconda Python remember, to activate your Python (base) environment.\n",
    "```text\n",
    "conda activate base\n",
    "```\n",
    "Then use *conda* to install gym.\n",
    "```text\n",
    "conda install -c conda-forge gym\n",
    "```\n",
    "\n",
    "Use *pip* for the standard Python install.\n",
    "\n",
    "```text\n",
    "pip install gym\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started with Gym ###\n",
    "Next, we will go through the [Getting Started with Gym](https://gym.openai.com/docs/) examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started Example 1 ###\n",
    "\n",
    "You may be excited to try the first example and see the cart and pole move around on your screen. I know that I was! However, there are problems rendering graphics from within the Jupyter environment. To circumvent these problems you can place the code in a .py file and then run Python on it from the terminal or command prompt window.\n",
    "\n",
    "\n",
    "```bash\n",
    "python cartpole1.py\n",
    "```\n",
    "\n",
    "Below is the contents pf the cartpol1.py file\n",
    "```python\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Started Example 2 ####\n",
    "\n",
    "Below is the second example. I used the same process to create a .py ilfe  \n",
    "```python\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()\n",
    "```\n",
    "\n",
    "Upon execution, this renders the cartpole problem until the 'done' flag is True and then starts over again. This is done 100 times. In addition to rendering a movie of the cart pole pole, it prints out the state information at each step and then the total number of steps executed until the done flag is set to true as shown below.\n",
    "\n",
    "![](Terminal2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example to create and intergate the environment ####\n",
    "1. Import the gym environment\n",
    "2. Instantiate the Cart Pole environment\n",
    "3. Print information on the observation space\n",
    "4. Print information about the action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Action Space: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "print('Observation Space:', env.observation_space)\n",
    "print('Action Space:', env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example to get the range of potential values in the observation space ####\n",
    "1. Print the largest values in the observation space\n",
    "2. Print the smallest values in the observation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high: [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "low:  [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print('high:',env.observation_space.high)\n",
    "print('low: ', env.observation_space.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example to see the initial values in the space ####\n",
    "Reset the observation space to place the cart and pole into an initial state. The four observation values are set to random small numbers to start the problem. These values will be different each time you start the problem. The four values are\n",
    "\n",
    "1. Position of the cart\n",
    "2. Velocity of the cart\n",
    "3. Angular position of the end of the pole\n",
    "4. Angular velocity of the end of the pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [-0.02678875  0.00897248  0.00754745  0.00851861]\n",
      "2. [0.03102953 0.02797914 0.02307276 0.0385354 ]\n",
      "3. [ 0.0315805  -0.02378612  0.04636732 -0.04458806]\n",
      "4. [ 0.04296029  0.02615685 -0.00586329  0.02069554]\n",
      "5. [-0.03098033 -0.00735531  0.02725083  0.02851875]\n"
     ]
    }
   ],
   "source": [
    "print(\"1.\", env.reset())\n",
    "print(\"2.\", env.reset())\n",
    "print(\"3.\", env.reset())\n",
    "print(\"4.\", env.reset())\n",
    "print(\"5.\", env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
